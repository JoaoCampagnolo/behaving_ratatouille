{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eabec8de",
   "metadata": {},
   "source": [
    "## Tubo de ensaio\n",
    "This is a sandbox notebook so I can test out some code and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315da0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89a30e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  4.,  6.,  8., 10.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums = np.linspace(0,10,11)\n",
    "nums[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694c91c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]] [[0. 0. 0.]\n",
      " [4. 4. 4.]\n",
      " [4. 4. 4.]] [[0. 0. 0.]\n",
      " [4. 4. 4.]\n",
      " [4. 4. 4.]] [[0.  0.5 0.5]\n",
      " [4.  4.5 4.5]\n",
      " [4.  4.5 4.5]]\n"
     ]
    }
   ],
   "source": [
    "A = np.ones((3,3))\n",
    "B = (np.array(A)*2)**2\n",
    "n = np.shape(B)[0]\n",
    "C = B\n",
    "C[::n] = 0\n",
    "D = C+np.transpose(C)/D.max()\n",
    "print(A,B,C,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47d509eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08333333, 0.08333333, 0.08333333, 0.16666667, 0.16666667,\n",
       "       0.08333333, 0.16666667, 0.16666667])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = D>0\n",
    "D[idx]/np.sum(D[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7627201c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bools = np.array([False, False, False, True, True, False, True, False])\n",
    "np.where(bools)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa6ceff",
   "metadata": {},
   "source": [
    "### Checking the pickle data from the experiments\n",
    "Files from Dimitris Mariatos. The file was created automatically by DLC Live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3745ef6c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 15)\n",
      "frame_time line 1: 1627213591.232682\n",
      "frame_time line 2: 1627213594.1510882\n",
      "frame_time line 3: 1627213603.3174865\n",
      "frame_time line 4: 1627213603.317511\n",
      "frame_time line 5: 1627213619.397348\n",
      "frame_time line 6: 1627213620.7130973\n",
      "frame_time line 7: 1627213621.4963899\n",
      "frame_time line 8: 1627213621.4964213\n",
      "frame_time line 9: 1627213658.59921\n",
      "frame_time line 10: 1627213659.348163\n",
      "frame_time line 11: 1627213659.970906\n",
      "frame_time line 12: 1627213659.9709349\n",
      "frame_time line 13: 1627213715.1696396\n",
      "frame_time line 14: 1627213716.6367238\n",
      "frame_time line 15: 1627213717.9677708\n",
      "frame_time line 16: 1627213717.967794\n",
      "frame_time line 17: 1627213765.7220788\n",
      "frame_time line 18: 1627213767.932468\n",
      "frame_time line 19: 1627213768.5088735\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from preprocess import h5_to_numpy\n",
    "import h5py\n",
    "\n",
    "fdis = 'C:\\\\Users\\\\olimp\\\\Documents\\\\ki_paper\\\\data\\\\375529_7\\\\thedata63.pkl'\n",
    "fpose = 'C:\\\\Users\\\\olimp\\\\Documents\\\\ki_paper\\\\data\\\\375529_7\\\\blackfly_375529_2021-07-25_7_DLC.hdf5'\n",
    "# distractions\n",
    "dis = pd.read_pickle(fdis)\n",
    "dis_columns = ['x','y','edges','opacity','radius','orientation','x','y','edges',\n",
    "               'opacity','radius','orientation','frame_time']\n",
    "# pose\n",
    "#pose = h5py.File(fpose,'r')\n",
    "pose = pd.read_hdf(fpose) #open the hdf5 file from DLC live\n",
    "pose.columns = ['snout_x','snout_y','snout_likelihood','left_ear_x','left_ear_y',\n",
    "                'left_ear_likelihood','right_ear_x','right_ear_y','right_ear_likelihood',\n",
    "                'tail_x','tail_y','tail_likelihood','frame_time','pose_time']\n",
    "\n",
    "print(np.shape(dis))\n",
    "ft = -1\n",
    "for i in range(1,20):\n",
    "    print(f'{dis_columns[ft]} line {i}: {dis[i][ft]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b08eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs_to_numpy(fpose):\n",
    "    '''\n",
    "    Takes a pose h5 dictionary generated by DLC Live (different from DLC standard) \n",
    "    and outputs a matrix with the shape: (# of pose landmarks * 2-3, depending on dims) X (# of frames)\n",
    "    '''\n",
    "    pose = pd.read_hdf(fpose) #open the hdf5 file from DLC live\n",
    "    pose.columns = ['snout_x','snout_y','snout_likelihood','left_ear_x','left_ear_y',\n",
    "                    'left_ear_likelihood','right_ear_x','right_ear_y','right_ear_likelihood',\n",
    "                    'tail_x','tail_y','tail_likelihood','frame_time','pose_time']\n",
    "    pose = np.transpose(pose.to_numpy())\n",
    "    n_cols = np.shape(pose)[0]\n",
    "    v_cols = np.arange(1,n_cols+1)\n",
    "    mask = np.ones(n_cols, dtype=bool)\n",
    "    mask = [not i%3==0 and i<=np.shape(pose)[1]-2 for i in v_cols] #ignore likelyhood, frame and pose time\n",
    "    return pose[mask] #don't forget you might need to transpose this matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfdcd4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 88325)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_matx = dfs_to_numpy(fpose)\n",
    "np.shape(pose_matx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "772f6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_trials(fdis, fpose):\n",
    "    '''\n",
    "    From two data frames, one from DLC live for pose and the other regarding the distractions,\n",
    "    yield two masks that match the number of pose frames:\n",
    "        -Validation mask: tracks the sequences of frames between the mouse pressing the task button\n",
    "        and it crossing the middle of the arena. The time stamps for such events are provided by\n",
    "        DLC live.\n",
    "        -Train mask: same thing but for sequences that occure between the mouse crossing the middle\n",
    "        of the arena and collecting its due reward.\n",
    "    '''\n",
    "    dis = pd.read_pickle(fdis)\n",
    "    pose = pd.read_hdf(fpose) #open the hdf5 file from DLC live\n",
    "    pose_frames = pose['frame_time']\n",
    "    dis_ti = [dis[i][-1] for i in range(1,np.shape(dis)[0],4)]\n",
    "    dis_tm = [dis[i][-1] for i in range(2,np.shape(dis)[0],4)]\n",
    "    dis_tf = [dis[i][-1] for i in range(3,np.shape(dis)[0],4)]\n",
    "    assert len(dis_ti) == len(dis_tm) == len(dis_tf)    \n",
    "    \n",
    "    val_mask = np.zeros(len(pose_frames), dtype=bool)\n",
    "    train_mask = np.zeros(len(pose_frames), dtype=bool)\n",
    "    j = 0\n",
    "    for i in range(len(val_mask)):\n",
    "        ti = dis_ti[j]; tm = dis_tm[j]; tf = dis_tf[j]\n",
    "        if pose_frames[i] >= ti and pose_frames[i] <= tm:\n",
    "            val_mask[i] = True\n",
    "        elif pose_frames[i] >= tm and pose_frames[i] <= tf:\n",
    "            train_mask[i] = True\n",
    "        elif pose_frames[i] > tf:\n",
    "            j+=1\n",
    "            if j == len(dis_ti):\n",
    "                print(f'Last trial ends at frame# {i} out of {len(pose_frames)}.')\n",
    "                break\n",
    "    return val_mask, train_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d7a57303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last trial ends at frame# 85865 out of 88325.\n",
      "8742\n",
      "3095\n"
     ]
    }
   ],
   "source": [
    "val_mask, train_mask = mask_trials(fdis, fpose)\n",
    "print(np.sum(val_mask))\n",
    "print(np.sum(train_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa604f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02aa39fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0: 0.15628890185484168\n",
      "index 1: 0.3641397746060996\n",
      "index 2: 4\n",
      "index 3: 0.0\n",
      "index 4: 0.025\n",
      "index 5: -10\n",
      "index 6: [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 '0']\n",
      " [-0.07862812716697404 0.4578981528397668 128 0.0 array(0.05) -10\n",
      "  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '0'], dtype=object)\n",
      "  0.14501461569509855 0.39166111607133236 3 0.0 array(0.025) -10 0\n",
      "  1627213591.232682]\n",
      " [-0.07862812716697404 0.4578981528397668 128 1.0 array(0.05) -10\n",
      "  array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '0'],\n",
      "         [-0.07862812716697404, 0.4578981528397668, 128, 0.0, array(0.05),\n",
      "          -10,\n",
      "          array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '0'], dtype=object),\n",
      "          0.14501461569509855, 0.39166111607133236, 3, 0.0, array(0.025),\n",
      "          -10, 0, 1627213591.232682]], dtype=object)\n",
      "  0.14501461569509855 0.39166111607133236 3 1.0 array(0.025) -10 0\n",
      "  1627213594.1510882]\n",
      " [-0.07862812716697404 0.4578981528397668 128 1.0 array(0.05) -10\n",
      "  array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '0'],\n",
      "         [-0.07862812716697404, 0.4578981528397668, 128, 0.0, array(0.05),\n",
      "          -10,\n",
      "          array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '0'], dtype=object),\n",
      "          0.14501461569509855, 0.39166111607133236, 3, 0.0, array(0.025),\n",
      "          -10, 0, 1627213591.232682],\n",
      "         [-0.07862812716697404, 0.4578981528397668, 128, 1.0, array(0.05),\n",
      "          -10,\n",
      "          array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '0'],\n",
      "                 [-0.07862812716697404, 0.4578981528397668, 128, 0.0, array(0.05),\n",
      "                  -10,\n",
      "                  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, '0'], dtype=object),\n",
      "                  0.14501461569509855, 0.39166111607133236, 3, 0.0, array(0.025),\n",
      "                  -10, 0, 1627213591.232682]], dtype=object)                           ,\n",
      "          0.14501461569509855, 0.39166111607133236, 3, 1.0, array(0.025),\n",
      "          -10, 0, 1627213594.1510882]], dtype=object)\n",
      "  0.14501461569509855 0.39166111607133236 3 1.0 array(0.025) -10 0\n",
      "  1627213603.3174865]\n",
      " [100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0 100.0\n",
      "  100.0 100.0 1627213603.317511]]\n",
      "index 7: 0.12153664692185134\n",
      "index 8: 0.2677905905091841\n",
      "index 9: 3\n",
      "index 10: 0.0\n",
      "index 11: 0.025\n",
      "index 12: -10\n",
      "index 13: 1\n",
      "index 14: 1627213619.397348\n"
     ]
    }
   ],
   "source": [
    "# index 6 (x of the 2nd stimulus) has an issue\n",
    "for i in range(15):\n",
    "    print(f'index {i}: {obj[5][i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadaf1d6",
   "metadata": {},
   "source": [
    "### Test embedding algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ca5e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open results\n",
    "import pickle\n",
    "\n",
    "# Select a directory\n",
    "res_dir = \"C:\\\\Users\\\\jhflc\\\\OneDrive\\\\Documentos\\\\Projects\\\\KI_article\\\\results\\\\19h38m_16_01_2022\\\\results_dict.pickle\"\n",
    "file = open(res_dir,'rb')\n",
    "obj = pickle.load(file)\n",
    "# Get the expression matrix to use:\n",
    "exp_matx = obj['Preprocess']['Data']['Exp_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d17d4acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c11bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dd24bbc",
   "metadata": {},
   "source": [
    "### Code junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2a266d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function1(pickle,hdf5):\n",
    "    '''reads the stimuli file from psychopy and the pose file from dlc\n",
    "    and merges them together. returns Two Dataframes merged1 and merged2\n",
    "    (one for every stimulus,there are two stimuli appearing in each trial)'''\n",
    "    #Begin by opening the stimulus data\n",
    "    k = read1(pickle) #open the pickle file with stimuli data\n",
    "    k.columns=['x','y','edges','opacity','radius','orientation','delete','x','y','edges','opacity','radius','orientation','laser','frame_time']\n",
    "    k = k.drop([0])\n",
    "    k.frame_time = k.frame_time.astype(float) #change the frame time into float     \n",
    "    k1=k.iloc[:,0:6] # first stimuli\n",
    "    k2=k.iloc[:,7:13] # second stimuli\n",
    "    k3 =k.iloc[:,13] # laser\n",
    "    k4 = k.iloc[:,14] # frame time\n",
    "    stim1 = pd.concat([k1, k3, k4], axis=1) #stimulus we are analysing\n",
    "    stim2 = pd.concat([k2, k3, k4], axis=1) #send stimuli to analyse\n",
    "    #Open the Pose file\n",
    "    df = pd.read_hdf(hdf5) #open the hdf5 file from DLC live\n",
    "    df.columns=['snout_x','snout_y','snout_likelihood','left_ear_x','left_ear_y',\n",
    "            'left_ear_likelihood','right_ear_x','right_ear_y','right_ear_likelihood',\n",
    "            'tail_x','tail_y','tail_likelihood','frame_time','pose_time'] #rename the columns from the DLC live file \n",
    "    dlc = df['frame_time']\n",
    "    Psychopy = stim2['frame_time']\n",
    "    dlc = dlc.astype(float)\n",
    "    Psychopy = Psychopy.astype(float)\n",
    "    Psychopy = Psychopy.reset_index()\n",
    "    Psychopy = Psychopy.drop(columns=['index'])\n",
    "    #merge stim1 and stim2 with df and create two dfs merged1 and merged2 (one for every stimulus)\n",
    "    merged1=frame_merger(stim1,df)\n",
    "    merged2=frame_merger(stim2,df)\n",
    "    return [merged1,merged2]\n",
    "\n",
    "def read1(name1):\n",
    "#k4 = k4 != 100\n",
    "    pkl_file = open(name1, 'rb')\n",
    "    dot = pickle.load(pkl_file)\n",
    "    dot = pd.DataFrame(dot)\n",
    "    return dot\n",
    "\n",
    "def frame_merger(stim,df):\n",
    "    stim['dlc_idx'] = np.nan # makes new coloumn in k for where the minimum's value is \n",
    "    for i in stim.index:\n",
    "        a = df.frame_time - stim.frame_time.loc[i]\n",
    "        idx = a.abs().idxmin()\n",
    "        stim.loc[i,'dlc_idx'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bda0e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " /\n",
      "   /df_with_missing\n",
      "     - /df_with_missing/axis0_label0\n",
      "     - /df_with_missing/axis0_label1\n",
      "     - /df_with_missing/axis0_level0\n",
      "     - /df_with_missing/axis0_level1\n",
      "     - /df_with_missing/axis1\n",
      "     - /df_with_missing/block0_items_label0\n",
      "     - /df_with_missing/block0_items_label1\n",
      "     - /df_with_missing/block0_items_level0\n",
      "     - /df_with_missing/block0_items_level1\n",
      "     - /df_with_missing/block0_values\n",
      "     - /df_with_missing/block1_items_label0\n",
      "     - /df_with_missing/block1_items_label1\n",
      "     - /df_with_missing/block1_items_level0\n",
      "     - /df_with_missing/block1_items_level1\n",
      "     - /df_with_missing/block1_values\n"
     ]
    }
   ],
   "source": [
    "def scan_hdf5(path, recursive=True, tab_step=2):\n",
    "    def scan_node(g, tabs=0):\n",
    "        print(' ' * tabs, g.name)\n",
    "        for k, v in g.items():\n",
    "            if isinstance(v, h5py.Dataset):\n",
    "                print(' ' * tabs + ' ' * tab_step + ' -', v.name)\n",
    "            elif isinstance(v, h5py.Group) and recursive:\n",
    "                scan_node(v, tabs=tabs + tab_step)\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        scan_node(f)\n",
    "        \n",
    "scan_hdf5(fpose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
